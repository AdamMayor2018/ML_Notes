# 一.双变量自动特征衍生

## 1.四则运算特征衍生

先从简单的方法开始讨论——四则运算特征衍生。该过程非常简单，就是单纯的选取两列进行四则运算，基本过程如下：

![image-20220120123540522](https://s2.loli.net/2022/01/20/hZOarqcndsHDxlV.png)

该过程并不复杂，实际代码执行过程也只需要单独索引出两列然后进行四则运算即可。一般来说，四则运算特征衍生的使用场景较为固定，主要有以下三个：

- 其一是用于创建业务补充字段：在某些数据集中，我们需要通过四则运算来创建具有明显业务含义的补充字段，例如在上述电信用户流失数据集中，我们可以通过将总消费金额除以用户入网时间，即可算出用户平均每月的消费金额，或者使用用户每月消费金额除以购买服务总数，则可算出每项服务的平均价格，这些字段有明确的业务含义，我们甚至可以将其视作原始字段；
- 其二，往往在特征衍生的所有工作结束后，我们会就这一系列衍生出来的新字段进行四则运算特征衍生，作为数据信息的一种补充；
- 其三，在某些极为特殊的字段创建过程中使用，例如竞赛中常用的黄金组合特征、流量平滑特征（稍后会重点讨论）等，需要使用四则运算进行特征衍生。

## 2.交叉组合特征衍生

- 方法介绍

  所谓交叉组合特征衍生，指的是不同分类变量不同取值水平之间进行交叉组合，从而创建新字段的过程。例如此前我们创建的老年且经济不独立的标识字段，实际上就是是否是老年人字段（SeniorCitizen）和是否经济独立字段（Dependents）两个字段交叉组合衍生过程中的一个：

![image-20220120140301256](https://s2.loli.net/2022/01/20/BiH4LtVTOjkWQuI.png)

不难看出，该计算流程并不复杂，需要注意的是，交叉组合后衍生的特征个数是参数交叉组合的特征的取值水平之积，因此交叉组合特征衍生一般只适用于取值水平较少的分类变量之间进行，若是分类变量或者取值水平较多的离散变量彼此之间进行交叉组合，则会导致衍生特征矩阵过于稀疏，从而无法为模型提供有效的训练信息。

- 代码封装：

```python
def cate_colName(Transformer, category_cols, drop='if_binary'):
    """
    离散字段独热编码后字段名创建函数
    
    :param Transformer: 独热编码转化器
    :param category_cols: 输入转化器的离散变量
    :param drop: 独热编码转化器的drop参数
    """
    
    cate_cols_new = []
    col_value = Transformer.categories_
    
    for i, j in enumerate(category_cols):
        if (drop == 'if_binary') & (len(col_value[i]) == 2):
            cate_cols_new.append(j)
        else:
            for f in col_value[i]:
                feature_name = j + '_' + f
                cate_cols_new.append(feature_name)
    return(cate_cols_new) 
```

```python
def Binary_Cross_Combination(colNames, features, OneHot=True):
    """
    分类变量两两组合交叉衍生函数
    
    :param colNames: 参与交叉衍生的列名称
    :param features: 原始数据集
    :param OneHot: 是否进行独热编码
    
    :return：交叉衍生后的新特征和新列名称
    """
    
    # 创建空列表存储器
    colNames_new_l = []
    features_new_l = []
    
    # 提取需要进行交叉组合的特征
    features = features[colNames]
    
    # 逐个创造新特征名称、新特征
    for col_index, col_name in enumerate(colNames):
        for col_sub_index in range(col_index+1, len(colNames)):
            
            newNames = col_name + '&' + colNames[col_sub_index]
            colNames_new_l.append(newNames)
            
            newDF = pd.Series(features[col_name].astype('str')  
                              + '&'
                              + features[colNames[col_sub_index]].astype('str'), 
                              name=col_name)
            features_new_l.append(newDF)
    
    # 拼接新特征矩阵
    features_new = pd.concat(features_new_l, axis=1)
    features_new.columns = colNames_new_l
    colNames_new = colNames_new_l
    
    # 对新特征矩阵进行独热编码
    if OneHot == True:
        enc = preprocessing.OneHotEncoder()
        enc.fit_transform(features_new)
        colNames_new = cate_colName(enc, colNames_new_l, drop=None)
        features_new = pd.DataFrame(enc.fit_transform(features_new).toarray(), columns=colNames_new)
        
    return features_new, colNames_new
```

调用方法：

```python
features_new, colNames_new = Binary_Cross_Combination(colNames, features)
df_temp = pd.concat([features, features_new], axis=1)
```

对于大多数批量创建特征的方法来说，创建的海量特征往往无效特征占绝大多数，例如此前我们曾手动验证过老年无伴侣字段就是无效字段。因此，如果不配合特征筛选方法、盲目带入大量无用特征进入模型，不仅不会起到正向的提升效果，往往可能还会适得其反。待后续介绍特征筛选方法后，我们再来看这些衍生出来的特征效用如何。

- 使用时注意事项

  在实际使用过程中，双变量的交叉衍生是最常见的特征衍生方法，也是第一梯队优先考虑的特征衍生的策略。通过不同分类水平的交叉衍生，能够极大程度丰富数据集信息呈现形式，同时也为有效信息的精细化筛选提供了更多可能。

&emsp;&emsp;但同时也需要注意，越多的分类特征进行交叉组合、或者参与交叉组合的特征本身分类水平更多，衍生的特征数量也将指数级上涨，例如有10个二分类变量参与交叉衍生，则最终将衍生出$2^{10}=1024$个新特征，而如果是10个三分类变量参与交叉衍生，则最终将衍生出$3^{10}=29049$个新特征。无论如何进行衍生，首先我们需要对衍生后的特征规模有基本判断。

## 3.分组统计特征衍生

所谓分组统计，顾名思义，就是A特征根据B特征的不同取值进行分组统计，统计量可以是均值、方差等针对连续变量的统计指标，也可以是众数、分位数等针对离散变量的统计指标。

该过程也并不复杂，在实际执行分组统计特征衍生的过程中（假设是A特征根据B特征的不同取值进行分组统计），有以下几点需要注意：

- 首先，一般来说A特征可以是离散变量也可以是连续变量，而B特征必须是离散变量，且最好是一些取值较多的离散变量（或者固定取值的连续变量），例如本数据集中的tenure字段，总共有73个取值。主要原因是如果B特征取值较少，则在衍生的特征矩阵中会出现大量的重复的行；      
- 其次，在实际计算A的分组统计量时，可以不局限于连续特征只用连续变量的统计量、离散特征只用离散的统计量，完全可以交叉使用，例如A是离散变量，我们也可以分组统计其均值、方差、偏度、峰度等，连续变量也可以统计众数、分位数等。很多时候，更多的信息组合有可能会带来更多的可能性；        
- 其三，有的时候分组统计还可以用于多表连接的场景，例如假设现在给出的数据集不是每个用户的汇总统计结果，而是每个用户在过去的一段时间内的行为记录，则我们可以根据用户ID对其进行分组统计汇总：        
<center><img src="https://s2.loli.net/2022/01/20/mE9hBtyaHpOIlvR.png" alt="image-20220120172058991" style="zoom:33%;" /> 

- 其四，很多时候我们还会考虑进一步围绕特征A和分组统计结果进行再一次的四则运算特征衍生，例如用月度消费金额减去分组均值，则可以比较每一位用户与相同时间入网用户的消费平均水平的差异，围绕衍生特征再次进行衍生，我们将其称为统计演变特征，也是分组汇总衍生特征的重要应用场景：     

<center><img src="https://s2.loli.net/2022/01/20/Z1bgnjBui7VT4dI.png" alt="image-20220120172703371" style="zoom:33%;" />  


**封装函数：**

```python
def Binary_Group_Statistics(keyCol, 
                            features, 
                            col_num=None, 
                            col_cat=None, 
                            num_stat=['mean', 'var', 'max', 'min', 'skew', 'median'], 
                            cat_stat=['mean', 'var', 'max', 'min', 'median', 'count', 'nunique'], 
                            quant=True):
    """
    双变量分组统计特征衍生函数
    
    :param keyCol: 分组参考的关键变量
    :param features: 原始数据集
    :param col_num: 参与衍生的连续型变量
    :param col_cat: 参与衍生的离散型变量
    :param num_stat: 连续变量分组统计量
    :param cat_num: 离散变量分组统计量  
    :param quant: 是否计算分位数  

    :return：交叉衍生后的新特征和新特征的名称
    """
    
    # 当输入的特征有连续型特征时
    if col_num != None:
        aggs_num = {}
        colNames = col_num
        
        # 创建agg方法所需字典
        for col in col_num:
            aggs_num[col] = num_stat 
            
        # 创建衍生特征名称列表
        cols_num = [keyCol]
        for key in aggs_num.keys():
            cols_num.extend([key+'_'+keyCol+'_'+stat for stat in aggs_num[key]])
            
        # 创建衍生特征df
        features_num_new = features[col_num+[keyCol]].groupby(keyCol).agg(aggs_num).reset_index()
        features_num_new.columns = cols_num 
        
        # 当输入的特征有连续型也有离散型特征时
        if col_cat != None:        
            aggs_cat = {}
            colNames = col_num + col_cat

            # 创建agg方法所需字典
            for col in col_cat:
                aggs_cat[col] = cat_stat

            # 创建衍生特征名称列表
            cols_cat = [keyCol]
            for key in aggs_cat.keys():
                cols_cat.extend([key+'_'+keyCol+'_'+stat for stat in aggs_cat[key]])    

            # 创建衍生特征df
            features_cat_new = features[col_cat+[keyCol]].groupby(keyCol).agg(aggs_cat).reset_index()
            features_cat_new.columns = cols_cat
    
            # 合并连续变量衍生结果与离散变量衍生结果
            df_temp = pd.merge(features_num_new, features_cat_new, how='left',on=keyCol)
            features_new = pd.merge(features[keyCol], df_temp, how='left',on=keyCol)
            features_new.loc[:, ~features_new.columns.duplicated()]
            colNames_new = cols_num + cols_cat
            colNames_new.remove(keyCol)
            colNames_new.remove(keyCol)
         
        # 当只有连续变量时
        else:
            # merge连续变量衍生结果与原始数据，然后删除重复列
            features_new = pd.merge(features[keyCol], features_num_new, how='left',on=keyCol)
            features_new.loc[:, ~features_new.columns.duplicated()]
            colNames_new = cols_num
            colNames_new.remove(keyCol)
    
    # 当没有输入连续变量时
    else:
        # 但存在分类变量时，即只有分类变量时
        if col_cat != None:
            aggs_cat = {}
            colNames = col_cat

            for col in col_cat:
                aggs_cat[col] = cat_stat

            cols_cat = [keyCol]
            for key in aggs_cat.keys():
                cols_cat.extend([key+'_'+keyCol+'_'+stat for stat in aggs_cat[key]])    

            features_cat_new = features[col_cat+[keyCol]].groupby(keyCol).agg(aggs_cat).reset_index()
            features_cat_new.columns = cols_cat            
             
            features_new = pd.merge(features[keyCol], features_cat_new, how='left',on=keyCol)
            features_new.loc[:, ~features_new.columns.duplicated()]
            colNames_new = cols_cat
            colNames_new.remove(keyCol) 
    
    if quant:
        # 定义四分位计算函数
        def q1(x):
            """
            下四分位数
            """
            return x.quantile(0.25)

        def q2(x):
            """
            上四分位数
            """
            return x.quantile(0.75)

        aggs = {}
        for col in colNames:
            aggs[col] = ['q1', 'q2']

        cols = [keyCol]
        for key in aggs.keys():
            cols.extend([key+'_'+keyCol+'_'+stat for stat in aggs[key]])    

        aggs = {}
        for col in colNames:
            aggs[col] = [q1, q2]    

        features_temp = features[colNames+[keyCol]].groupby(keyCol).agg(aggs).reset_index()
        features_temp.columns = cols

        features_new = pd.merge(features_new, features_temp, how='left',on=keyCol)
        features_new.loc[:, ~features_new.columns.duplicated()]
        colNames_new = colNames_new + cols
        colNames_new.remove(keyCol)     
    
    features_new.drop([keyCol], axis=1, inplace=True)
        
    return features_new, colNames_new
```

## 4.多项式特征衍生

- 方法介绍

  当然，双变量的多项式衍生会比单变量多项式衍生更有效果，该过程并不复杂，只是在单变量多项式衍生基础上增加了交叉项的计算，例如X1和X2都是某连续变量，在进行双变量二阶多项式衍生时计算过程如下：

![image-20220120222202519](https://s2.loli.net/2022/01/20/MKXbm2tpf1hFVRw.png)

更高阶的多项式衍生过程也依此类推。在实际使用过程中，有以下几点注意事项：

- 一般来说双变量多项式衍生只适用于两个连续变量之间，一个连续变量一个离散变量或者两个离散变量进行多项式衍生意义不大（除非类似tenure字段，离散字段带有非常多不同的取值）；
- 在选取特征进行多项式衍生的过程中，往往我们不会随意组合连续变量来进行多项式衍生，而是只针对我们判断非常重要的特征来进行多项式衍生。就这点而言，多项式衍生和四则运算衍生非常类似，其使用场景背后的基本思路也完全一致：强化重要特征的表现形式；
- 关于衍生多少阶，一般来说伴随着多项式阶数的增加，各列数值也会呈现指数级递增（或递减），因此往往我们只会衍生3阶左右，极少数情况会衍生5-10阶。而伴随着多项式阶数的增加，也需要配合一些手段来消除数值绝对值爆炸或者衰减所造成的影响，例如对数据进行归一化处理等；

- 实现过程

  而多项式衍生的实现过程也并不复杂，我们可以直接调用sklearn中的PolynomialFeatures来执行相关操作：

**封装函数：**

```python
def Binary_PolynomialFeatures(colNames, degree, features):
    """
    连续变量两变量多项式衍生函数
    
    :param colNames: 参与交叉衍生的列名称
    :param degree: 多项式最高阶
    :param features: 原始数据集
    
    :return：交叉衍生后的新特征和新列名称
    """
    
    
    # 创建空列表存储器
    colNames_new_l = []
    features_new_l = []
    
    # 提取需要进行多项式衍生的特征
    features = features[colNames]
    
    # 逐个进行多项式特征组合
    for col_index, col_name in enumerate(colNames):
        for col_sub_index in range(col_index+1, len(colNames)):
            col_temp = [col_name] + [colNames[col_sub_index]]
            array_new_temp = PolynomialFeatures(degree=degree, include_bias=False).fit_transform(features[col_temp])
            features_new_l.append(pd.DataFrame(array_new_temp[:, 2:]))
    
            # 逐个创建衍生多项式特征的名称
            for deg in range(2, degree+1):
                for i in range(deg+1):
                    col_name_temp = col_temp[0] + '**' + str(deg-i) + '*'+ col_temp[1] + '**' + str(i)
                    colNames_new_l.append(col_name_temp)
            
    
    # 拼接新特征矩阵
    features_new = pd.concat(features_new_l, axis=1)
    features_new.columns = colNames_new_l
    colNames_new = colNames_new_l
    
    return features_new, colNames_new
```

## 5.统计演变特征

- 二阶特征衍生

  一种很自然的联想，是当我们已经完成了一些特征衍生后，还会考虑以衍生特征为基础，进一步进行特征衍生，这也就是所谓的二阶特征衍生（注意区分二阶多项式衍生）。当然这个过程可以无限重复，这也是此前讨论为何会出现无限特征的根本原因之一。不过，在大多数情况下，二阶甚至是更高阶的特征衍生（以下简称高阶特征衍生）往往伴随着严重的信息衰减，大多数高阶衍生出来的特征其本身的有效性也将急剧下降，外加高阶特征衍生是在已有的大量衍生出来的一阶特征基础上再进行衍生，其计算过程往往需要消耗巨大的计算量，外加需要从一系列高阶衍生特征中挑选出极个别有用的特征也较为繁琐，因此，高阶衍生往往性价比较低，除非特殊情况，否则并不建议在广泛特征基础上进行大量高阶特征衍生的尝试。

- 统计演变特征

  当然，尽管并不建议手动进行尝试，但在长期的实践过程中，人们还是总结出某些高阶衍生特征（主要是二阶衍生特征）在很多情况下都能起到很好的效果。需要注意的是，这里的着重指的是一些特征，而不是特征衍生的策略。在这些普遍有效的高阶特征中，最著名的就是所谓的统计演变特征，这些特征由原始特征和分组统计特征、或分组统计特征彼此之间交叉衍生而来，在很多算法竞赛和企业应用中，都被证明了有较高的尝试价值。

**函数封装：**

```python
def Group_Statistics_Extension(colNames, keyCol, features):
    """
    双变量分组统计二阶特征衍生函数
    
    :param colNames: 参与衍生的特征
    :param keyCol: 分组参考的关键变量
    :param features: 原始数据集
    
    :return：交叉衍生后的新特征和新列名称
    """
    
    # 定义四分位计算函数
    def q1(x):
        """
        下四分位数
        """
        return x.quantile(0.25)

    def q2(x):
        """
        上四分位数
        """
        return x.quantile(0.75)   
    
    # 一阶特征衍生
    # 先定义用于生成列名称的aggs
    aggs = {}    
    for col in colNames:
        aggs[col] = ['mean', 'var', 'median', 'q1', 'q2']       
    cols = [keyCol]
    for key in aggs.keys():
        cols.extend([key+'_'+keyCol+'_'+stat for stat in aggs[key]])

    # 再定义用于进行分组汇总的aggs
    aggs = {}   
    for col in colNames:
        aggs[col] = ['mean', 'var', 'median', q1, q2] 
           
    features_new = features[colNames+[keyCol]].groupby(keyCol).agg(aggs).reset_index()
    features_new.columns = cols
             
    features_new = pd.merge(features[keyCol], features_new, how='left',on=keyCol)
    features_new.loc[:, ~features_new.columns.duplicated()]
    colNames_new = cols
    colNames_new.remove(keyCol)
    col1 = colNames_new.copy()
    print(col1)
    
    # 二阶特征衍生
    # 流量平滑特征
    for col_temp in colNames:
        col = col_temp+'_'+keyCol+'_'+'mean'
        features_new[col_temp+'_dive1_'+col] = features_new[keyCol] / (features_new[col] + 1e-5)
        colNames_new.append(col_temp+'_dive1_'+col)
        col = col_temp+'_'+keyCol+'_'+'median'
        features_new[col_temp+'_dive2_'+col] = features_new[keyCol] / (features_new[col] + 1e-5)
        colNames_new.append(col_temp+'_dive2_'+col)
        
    # 黄金组合特征
    for col_temp in colNames:
        col = col_temp+'_'+keyCol+'_'+'mean'
        features_new[col_temp+'_minus1_'+col] = features_new[keyCol] - features_new[col] 
        colNames_new.append(col_temp+'_minus1_'+col)
        features_new[col_temp+'_minus2_'+col] = features_new[keyCol] - features_new[col] 
        colNames_new.append(col_temp+'_minus2_'+col)
        
    # 组内归一化特征
    for col_temp in colNames:
        col_mean = col_temp+'_'+keyCol+'_'+'mean'
        col_var = col_temp+'_'+keyCol+'_'+'var'
        features_new[col_temp+'_norm_'+keyCol] = (features_new[keyCol] - features_new[col_mean]) / (np.sqrt(features_new[col_var]) + 1e-5)      
        colNames_new.append(col_temp+'_norm_'+keyCol)
    
    # Gap特征
    for col_temp in colNames:
        col_q1 = col_temp+'_'+keyCol+'_'+'q1'
        col_q2 = col_temp+'_'+keyCol+'_'+'q2'
        features_new[col_temp+'_gap_'+keyCol] = features_new[col_q2] - features_new[col_q1]  
        colNames_new.append(col_temp+'_gap_'+keyCol)
        
    # 数据倾斜特征
    for col_temp in colNames:
        col_mean = col_temp+'_'+keyCol+'_'+'mean'
        col_median = col_temp+'_'+keyCol+'_'+'median'
        features_new[col_temp+'_mag1_'+keyCol] = features_new[col_median] - features_new[col_mean]    
        colNames_new.append(col_temp+'_mag1_'+keyCol)
        features_new[col_temp+'_mag2_'+keyCol] = features_new[col_median] / (features_new[col_mean] + 1e-5)
        colNames_new.append(col_temp+'_mag2_'+keyCol)
        
    # 变异系数
    for col_temp in colNames:
        col_mean = col_temp+'_'+keyCol+'_'+'mean'
        col_var = col_temp+'_'+keyCol+'_'+'var'
        features_new[col_temp+'_cv_'+keyCol] = np.sqrt(features_new[col_var]) / (features_new[col_mean] + 1e-5)
        colNames_new.append(col_temp+'_cv_'+keyCol)

    features_new.drop([keyCol], axis=1, inplace=True)
    features_new.drop(col1, axis=1, inplace=True)
    colNames_new = list(features_new.columns)
    
    return features_new, colNames_new
```

